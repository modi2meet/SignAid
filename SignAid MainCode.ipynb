{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7a43986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import cv2\n",
    "from pytube import YouTube\n",
    "import shutil\n",
    "import math\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a630055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#checking for device\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5871327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms\n",
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "                        [0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d7f9403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader\n",
    "train_path = r'C:\\\\Users\\\\User\\\\meet modi\\\\CNN\\\\asl_alphabet_train'\n",
    "test_path = r'C:\\\\Users\\\\User\\\\meet modi\\\\CNN\\\\asl_alphabet_test\\\\asl_alphabet_test'\n",
    "\n",
    "\n",
    "train_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ca961a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "#categories\n",
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c231b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Network\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=6):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #Output size after convolution filter\n",
    "        #((w-f+2P)/s) +1\n",
    "        \n",
    "        #Input shape= (256,3,150,150)\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,12,150,150)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        #Shape= (256,12,150,150)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #Shape= (256,12,150,150)\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size be factor 2\n",
    "        #Shape= (256,12,75,75)\n",
    "        \n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,20,75,75)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Shape= (256,20,75,75)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,32,75,75)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        #Shape= (256,32,75,75)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #Shape= (256,32,75,75)\n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Feed forwad function\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "            \n",
    "            \n",
    "            #Above output will be in matrix form, with shape (256,32,75,75)\n",
    "            \n",
    "        output=output.view(-1,32*75*75)\n",
    "            \n",
    "            \n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6ca404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes = 26).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfb70038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optmizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ced7767",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76c2edb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78000\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "train_count = len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count = len(glob.glob(test_path+'/**/*.jpg'))\n",
    "print(train_count)\n",
    "print(test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34cb8b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(2.4643) Train Accuracy: 0.6337948717948718 Test Accuracy: 0.9230769230769231\n",
      "Epoch: 1 Train Loss: tensor(0.2894) Train Accuracy: 0.9055641025641026 Test Accuracy: 1.0\n",
      "Epoch: 2 Train Loss: tensor(0.1758) Train Accuracy: 0.9421153846153846 Test Accuracy: 1.0\n",
      "Epoch: 3 Train Loss: tensor(0.1314) Train Accuracy: 0.9572820512820512 Test Accuracy: 0.9615384615384616\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11384/1843503778.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mimages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    230\u001b[0m         \"\"\"\n\u001b[0;32m    231\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Model training and saving best model\n",
    "\n",
    "best_accuracy=0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "    \n",
    "    \n",
    "    # Evaluation on testing dataset\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy=0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        outputs=model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    test_accuracy=test_accuracy/test_count\n",
    "    \n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "    \n",
    "    #Save the best model\n",
    "    if test_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "        best_accuracy=test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fbc3cc",
   "metadata": {},
   "source": [
    "# Open youtube in browser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4686d48",
   "metadata": {},
   "source": [
    "Manually search your video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b97eb3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 99.0.4844\n",
      "Get LATEST chromedriver version for 99.0.4844 google-chrome\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/99.0.4844.51/chromedriver_win32.zip\n",
      "Driver has been saved in cache [C:\\Users\\User\\.wdm\\drivers\\chromedriver\\win32\\99.0.4844.51]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12136/4286413383.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.get('https://www.youtube.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc6876d",
   "metadata": {},
   "source": [
    "# Extract the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f685a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "for i in range(0, len(driver.window_handles), 1):\n",
    "    driver.switch_to.window(driver.window_handles[i])\n",
    "    urls.append(driver.current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89c6a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = urls[0]\n",
    "length = len(url)\n",
    "rst = url.find('=')\n",
    "video_id = url[rst+1:length]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f73e94c",
   "metadata": {},
   "source": [
    "# Download the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaa4581f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12136/3774708678.py:2: DeprecationWarning: Call to deprecated function all (This object can be treated as a list, all() is useless).\n",
      "  video.streams.filter(file_extension = \"mp4\").all()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"24fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">,\n",
       " <Stream: itag=\"22\" mime_type=\"video/mp4\" res=\"720p\" fps=\"24fps\" vcodec=\"avc1.64001F\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">,\n",
       " <Stream: itag=\"137\" mime_type=\"video/mp4\" res=\"1080p\" fps=\"24fps\" vcodec=\"avc1.640028\" progressive=\"False\" type=\"video\">,\n",
       " <Stream: itag=\"136\" mime_type=\"video/mp4\" res=\"720p\" fps=\"24fps\" vcodec=\"avc1.64001f\" progressive=\"False\" type=\"video\">,\n",
       " <Stream: itag=\"135\" mime_type=\"video/mp4\" res=\"480p\" fps=\"24fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">,\n",
       " <Stream: itag=\"134\" mime_type=\"video/mp4\" res=\"360p\" fps=\"24fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">,\n",
       " <Stream: itag=\"133\" mime_type=\"video/mp4\" res=\"240p\" fps=\"24fps\" vcodec=\"avc1.4d4015\" progressive=\"False\" type=\"video\">,\n",
       " <Stream: itag=\"160\" mime_type=\"video/mp4\" res=\"144p\" fps=\"24fps\" vcodec=\"avc1.4d400c\" progressive=\"False\" type=\"video\">,\n",
       " <Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">,\n",
       " <Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = YouTube(url)\n",
    "video.streams.filter(file_extension = \"mp4\").all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f8a863b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\meet modi\\\\CNN\\\\The secret soundtrack of the sea  Steve Simpson  TEDxExeter.mp4'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.streams.get_by_itag(18).download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53722df3",
   "metadata": {},
   "source": [
    "# Download transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b94f1f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (Temp/ipykernel_12136/3516762036.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12136/3516762036.py\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    print(transpt)\\n\",\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "srt = YouTubeTranscriptApi.get_transcript(str(video_id))\n",
    "with open('readme.txt', 'w') as f:\n",
    "    for x in range(len(srt)):\n",
    "        with open('readme.txt', 'a') as f:\n",
    "            \n",
    "            transpt = srt[x]['text']\n",
    "#             print(transpt)\\n\",\n",
    "            f.write(transpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9644be81",
   "metadata": {},
   "source": [
    "To make a csv file to write the timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa061d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('readme1.txt', 'w') as f:\n",
    "    with open('readme.txt') as infile, open('readme1.txt', \"a\") as outfile:\n",
    "        for line in infile:\n",
    "            outfile.write(\"n\" + line.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4917d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO WORLD\n",
      "MY NAME IS SYED ABOU\n",
      "REJIN HELPED ME\n",
      "MAHIMAN IS AN INTELLIGENT STUDENT\n"
     ]
    }
   ],
   "source": [
    "# reading each line\n",
    "with open('readme2.txt','r') as file:\n",
    "    for line in file:\n",
    "#         print(len(line))\n",
    "#         word = line.split()\n",
    "        line = line.strip(\"\\n\")\n",
    "#         print(word[1])\n",
    "\n",
    "        print(line)\n",
    "\n",
    "\n",
    "        l = len(line)\n",
    "#         print(\"length of word:\",l)\n",
    "        canvas = np.full((100,100*l,3),0,dtype = 'uint8')\n",
    "        \n",
    "        for j,character in enumerate(line):\n",
    "            w = character\n",
    "#             print(w)\n",
    "            if w == \"\":\n",
    "                pass\n",
    "            else:\n",
    "                image_list = []\n",
    "                path = test_path + character\n",
    "                path = path[0:len(path)-1]+\"\\\\\" + path[-1] + \"\\\\\" + \"*.jpg\"\n",
    "                for i in glob.glob(path):\n",
    "                    image = cv2.imread(str(i))\n",
    "                    image = cv2.resize(image,(100, 100))\n",
    "                    \n",
    "#                     print(j)\n",
    "                    canvas[0:100,j*100:(j*100)+100,::] = image\n",
    "                    \n",
    "#                     for j in range(len(line)):\n",
    "#                         imgHor = np.hstack(image_list[j,:])\n",
    "#                     #img = image_list[1:character]\n",
    "#                     cv2.imshow(\"image\",image)\n",
    "#                     cv2.waitKey(500)\n",
    "        \n",
    "        cv2.imshow(\"canvas\",canvas)\n",
    "        cv2.waitKey(1000)\n",
    "        cv2.destroyAllWindows()\n",
    "                    \n",
    "                \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e8873bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Title: Got Millet? How Marketing Could Improve the Lives of African Farmers | ZoÃ« Karl-Waithaka | TED\n",
      "Duration: 10.95 minutes\n",
      "Rating: None\n",
      "# of views: 9721\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(f'Title: {video.title}')\n",
    "print(f'Duration: {video.length / 60:.2f} minutes')\n",
    "print(f'Rating: {video.rating:}')\n",
    "print(f'# of views: {video.views}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "81376b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.08\n",
      "4.64\n",
      "6.96\n",
      "10.08\n",
      "20.48\n",
      "24.0\n",
      "26.48\n",
      "28.8\n",
      "31.599\n",
      "33.2\n",
      "35.44\n",
      "37.84\n",
      "39.84\n",
      "42.32\n",
      "44.399\n",
      "46.239\n",
      "47.76\n",
      "50.0\n",
      "51.84\n",
      "54.32\n",
      "56.079\n",
      "58.879\n",
      "61.28\n",
      "63.76\n",
      "65.84\n",
      "67.36\n",
      "69.36\n",
      "70.72\n",
      "73.119\n",
      "75.28\n",
      "76.799\n",
      "78.88\n",
      "80.4\n",
      "82.64\n",
      "84.56\n",
      "86.72\n",
      "89.2\n",
      "90.72\n",
      "92.72\n",
      "95.2\n",
      "98.159\n",
      "100.72\n",
      "103.759\n",
      "105.52\n",
      "108.72\n",
      "109.84\n",
      "111.119\n",
      "113.52\n",
      "115.6\n",
      "117.52\n",
      "119.6\n",
      "121.6\n",
      "126.32\n",
      "128.64\n",
      "131.12\n",
      "133.12\n",
      "135.52\n",
      "138.4\n",
      "139.76\n",
      "142.64\n",
      "144.319\n",
      "146.08\n",
      "148.08\n",
      "151.84\n",
      "154.48\n",
      "156.48\n",
      "159.04\n",
      "163.28\n",
      "165.12\n",
      "166.239\n",
      "168.64\n",
      "170.879\n",
      "172.319\n",
      "174.16\n",
      "176.72\n",
      "179.76\n",
      "182.64\n",
      "185.68\n",
      "188.159\n",
      "190.56\n",
      "193.599\n",
      "196.239\n",
      "198.159\n",
      "199.92\n",
      "202.239\n",
      "204.56\n",
      "206.08\n",
      "209.12\n",
      "210.84\n",
      "214.159\n",
      "216.08\n",
      "218.799\n",
      "221.36\n",
      "224.0\n",
      "224.84\n",
      "228.0\n",
      "230.4\n",
      "232.56\n",
      "234.56\n",
      "235.36\n",
      "238.64\n",
      "242.0\n",
      "244.72\n",
      "246.72\n",
      "248.159\n",
      "249.76\n",
      "251.92\n",
      "254.56\n",
      "256.239\n",
      "259.04\n",
      "261.6\n",
      "263.68\n",
      "265.759\n",
      "268.0\n",
      "270.72\n",
      "272.72\n",
      "274.8\n",
      "276.24\n",
      "278.72\n",
      "281.28\n",
      "282.4\n",
      "284.16\n",
      "286.88\n",
      "289.04\n",
      "291.04\n",
      "293.84\n",
      "296.08\n",
      "299.68\n",
      "301.759\n",
      "303.759\n",
      "306.24\n",
      "309.12\n",
      "311.36\n",
      "315.68\n",
      "318.16\n",
      "319.84\n",
      "322.08\n",
      "324.0\n",
      "327.28\n",
      "328.96\n",
      "330.96\n",
      "333.36\n",
      "335.12\n",
      "338.0\n",
      "341.36\n",
      "343.52\n",
      "346.639\n",
      "349.6\n",
      "351.36\n",
      "353.6\n",
      "356.24\n",
      "357.12\n",
      "359.12\n",
      "360.639\n",
      "363.84\n",
      "367.039\n",
      "369.44\n",
      "371.12\n",
      "373.6\n",
      "375.12\n",
      "377.28\n",
      "378.4\n",
      "380.96\n",
      "383.52\n",
      "386.08\n",
      "388.96\n",
      "391.199\n",
      "392.8\n",
      "395.52\n",
      "397.84\n",
      "399.919\n",
      "402.08\n",
      "404.639\n",
      "407.039\n",
      "409.919\n",
      "413.199\n",
      "415.28\n",
      "417.84\n",
      "420.08\n",
      "421.68\n",
      "424.88\n",
      "427.28\n",
      "429.52\n",
      "431.199\n",
      "433.44\n",
      "437.199\n",
      "439.12\n",
      "441.199\n",
      "443.759\n",
      "446.0\n",
      "448.479\n",
      "451.68\n",
      "453.68\n",
      "456.319\n",
      "460.319\n",
      "462.639\n",
      "464.72\n",
      "466.8\n",
      "469.36\n",
      "471.12\n",
      "473.919\n",
      "475.039\n",
      "477.039\n",
      "479.52\n",
      "482.72\n",
      "484.879\n",
      "486.879\n",
      "488.72\n",
      "490.879\n",
      "494.879\n",
      "497.68\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12136/1104564028.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The float list is : \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "srt = YouTubeTranscriptApi.get_transcript(str(video_id))\n",
    "for x in range(len(srt)):\n",
    "    index = srt[x]['start']\n",
    "    print (index)\n",
    "    \n",
    "res = [float(idx) for idx in index.split('\\n ')]\n",
    "print(\"The float list is : \" + str(res))\n",
    "print(res[0])\n",
    "# with open('start.txt', 'w') as f:\n",
    "#     for x in range(len(srt)):\n",
    "#         transpt = srt[x]['start']\n",
    "# #     print(transpt)\n",
    "#         with open('start.txt', 'a') as f:       \n",
    "#             print(transpt)\n",
    "#             f.write(str(transpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6cb91044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': \"a quick new idea daily from the world's\", 'start': 2.08, 'duration': 4.88}, {'text': 'greatest tedx talks', 'start': 4.64, 'duration': 5.44}, {'text': \"i'm your host tosa leone and this\", 'start': 6.96, 'duration': 6.84}, {'text': 'is tedx shorts', 'start': 10.08, 'duration': 3.72}, {'text': 'most of us think of the ocean as quiet', 'start': 20.48, 'duration': 6.0}, {'text': 'when in reality the ocean has a very', 'start': 24.0, 'duration': 4.8}, {'text': 'complex soundscape that marine life', 'start': 26.48, 'duration': 5.119}, {'text': 'relies on to communicate and thrive', 'start': 28.8, 'duration': 4.4}, {'text': 'and the biggest threat to this delicate', 'start': 31.599, 'duration': 3.841}, {'text': 'soundscape comes from man-made noise', 'start': 33.2, 'duration': 4.64}, {'text': 'affecting oceanic life in', 'start': 35.44, 'duration': 4.4}, {'text': 'catastrophic ways', 'start': 37.84, 'duration': 4.48}, {'text': 'marine biologist steve simpson', 'start': 39.84, 'duration': 4.559}, {'text': 'specializes in the impact of these', 'start': 42.32, 'duration': 3.919}, {'text': 'man-made disruptions to marine', 'start': 44.399, 'duration': 3.361}, {'text': 'ecosystems', 'start': 46.239, 'duration': 3.761}, {'text': 'and today he suggests we listen closely', 'start': 47.76, 'duration': 4.08}, {'text': 'to the soundtrack of the ocean to', 'start': 50.0, 'duration': 4.32}, {'text': 'understand how important it is for our', 'start': 51.84, 'duration': 4.239}, {'text': 'aquatic life', 'start': 54.32, 'duration': 4.559}, {'text': 'the reef is alive with noise and that', 'start': 56.079, 'duration': 5.201}, {'text': \"noise has patterns and we've explored\", 'start': 58.879, 'duration': 4.881}, {'text': 'this by combining recordings with', 'start': 61.28, 'duration': 4.56}, {'text': 'underwater surveys', 'start': 63.76, 'duration': 3.6}, {'text': 'and with our underwater surveys we', 'start': 65.84, 'duration': 3.52}, {'text': 'realize that we can hear', 'start': 67.36, 'duration': 3.36}, {'text': 'whether there are coral there we can', 'start': 69.36, 'duration': 3.759}, {'text': 'hear which species live there we realize', 'start': 70.72, 'duration': 4.56}, {'text': 'that the fish at sea are doing much what', 'start': 73.119, 'duration': 3.68}, {'text': 'we would do if we were moving to a new', 'start': 75.28, 'duration': 3.6}, {'text': \"city we'd perhaps get on the internet\", 'start': 76.799, 'duration': 3.601}, {'text': 'and do some research into different', 'start': 78.88, 'duration': 3.76}, {'text': 'suburbs that we might want to live in we', 'start': 80.4, 'duration': 4.16}, {'text': 'think fish can do the same thing by', 'start': 82.64, 'duration': 4.08}, {'text': 'listening to their environment and', 'start': 84.56, 'duration': 4.64}, {'text': 'choosing where they want to live', 'start': 86.72, 'duration': 4.0}, {'text': 'we now know that reefs all sound', 'start': 89.2, 'duration': 3.52}, {'text': 'different they have signature sounds', 'start': 90.72, 'duration': 4.48}, {'text': 'baby fish can select the best habitat', 'start': 92.72, 'duration': 5.439}, {'text': 'for their kind by using sound and', 'start': 95.2, 'duration': 5.52}, {'text': 'amazingly it turns out so can many other', 'start': 98.159, 'duration': 5.6}, {'text': 'animals on coral reefs crabs lobsters', 'start': 100.72, 'duration': 4.8}, {'text': 'clams oysters', 'start': 103.759, 'duration': 4.961}, {'text': 'even corals themselves', 'start': 105.52, 'duration': 4.32}, {'text': \"now i'm going to take you to a few\", 'start': 108.72, 'duration': 2.399}, {'text': \"places that we've worked this is\", 'start': 109.84, 'duration': 3.68}, {'text': 'balikasag which is a marine protected', 'start': 111.119, 'duration': 4.481}, {'text': \"area in the philippines you can see it's\", 'start': 113.52, 'duration': 4.0}, {'text': \"full of life it's highly protected\", 'start': 115.6, 'duration': 4.0}, {'text': \"there's no fishing and as a result when\", 'start': 117.52, 'duration': 4.08}, {'text': 'we listen to it', 'start': 119.6, 'duration': 5.519}, {'text': \"it's a wonderful soundscape\", 'start': 121.6, 'duration': 3.519}, {'text': 'you can hear the fish communicating you', 'start': 126.32, 'duration': 4.8}, {'text': 'can hear the snapping shrimp', 'start': 128.64, 'duration': 4.48}, {'text': 'now sadly if we go three bays around the', 'start': 131.12, 'duration': 4.4}, {'text': 'corner to balang balangan', 'start': 133.12, 'duration': 5.28}, {'text': 'we find a more typical filipino reef', 'start': 135.52, 'duration': 4.24}, {'text': \"this is a reef that's been heavily\", 'start': 138.4, 'duration': 4.24}, {'text': 'overfished so there are no herbivores to', 'start': 139.76, 'duration': 4.559}, {'text': 'graze away at the algae which now', 'start': 142.64, 'duration': 3.44}, {'text': 'smothers the reef', 'start': 144.319, 'duration': 3.761}, {'text': 'you can even see craters from dynamite', 'start': 146.08, 'duration': 5.36}, {'text': 'fishing and when we listen to it', 'start': 148.08, 'duration': 3.36}, {'text': 'you can just about hear it so a tiny', 'start': 151.84, 'duration': 4.64}, {'text': 'fish would have to pretty much swim into', 'start': 154.48, 'duration': 4.56}, {'text': 'this reef before it found it the next', 'start': 156.48, 'duration': 6.64}, {'text': 'generation are not coming home', 'start': 159.04, 'duration': 4.08}, {'text': 'we are changing the soundtrack of the', 'start': 163.28, 'duration': 2.959}, {'text': 'ocean', 'start': 165.12, 'duration': 3.52}, {'text': 'through overfishing and poor', 'start': 166.239, 'duration': 4.64}, {'text': 'environmental protection', 'start': 168.64, 'duration': 3.679}, {'text': \"let's go somewhere better let's go to\", 'start': 170.879, 'duration': 3.281}, {'text': 'the great barrier reef this is from', 'start': 172.319, 'duration': 4.401}, {'text': 'marine biologists the benchmark this is', 'start': 174.16, 'duration': 5.6}, {'text': 'where we go to see what coral reefs once', 'start': 176.72, 'duration': 5.92}, {'text': 'were like what coral reefs can be like', 'start': 179.76, 'duration': 5.92}, {'text': 'with really effective management highly', 'start': 182.64, 'duration': 5.519}, {'text': 'protected marine reserves long distances', 'start': 185.68, 'duration': 4.88}, {'text': 'away from cities from pollution', 'start': 188.159, 'duration': 5.44}, {'text': 'and as a result beautiful bustling', 'start': 190.56, 'duration': 5.679}, {'text': 'underwater cities full of life', 'start': 193.599, 'duration': 4.56}, {'text': \"you can hear the great barrier reef it's\", 'start': 196.239, 'duration': 3.681}, {'text': 'a wonderful thing', 'start': 198.159, 'duration': 4.08}, {'text': \"and we've studied this for 15 years to\", 'start': 199.92, 'duration': 4.64}, {'text': 'make reference to the reefs around the', 'start': 202.239, 'duration': 3.841}, {'text': 'world', 'start': 204.56, 'duration': 4.56}, {'text': 'at least we have until three years ago', 'start': 206.08, 'duration': 4.76}, {'text': 'when tragedy', 'start': 209.12, 'duration': 5.039}, {'text': 'struck with painful predictability we', 'start': 210.84, 'duration': 5.24}, {'text': 'saw the water temperatures starting to', 'start': 214.159, 'duration': 4.64}, {'text': 'rise oceanographic conditions meant the', 'start': 216.08, 'duration': 5.28}, {'text': 'water was staying in one location', 'start': 218.799, 'duration': 5.201}, {'text': 'and for three weeks the great barrier', 'start': 221.36, 'duration': 3.48}, {'text': 'reef', 'start': 224.0, 'duration': 4.0}, {'text': 'cooked we saw the reef in front of our', 'start': 224.84, 'duration': 5.56}, {'text': 'eyes dying and when we go back to the', 'start': 228.0, 'duration': 4.56}, {'text': 'great barrier reef now the snapping', 'start': 230.4, 'duration': 4.16}, {'text': 'shrimp have gone', 'start': 232.56, 'duration': 2.8}, {'text': 'the', 'start': 234.56, 'duration': 4.08}, {'text': 'complexity the diversity of the sound is', 'start': 235.36, 'duration': 6.64}, {'text': \"missing it's become an acoustic desert\", 'start': 238.64, 'duration': 6.08}, {'text': 'and so we realize with climate change', 'start': 242.0, 'duration': 4.72}, {'text': 'we are changing the soundtrack of the', 'start': 244.72, 'duration': 3.439}, {'text': 'ocean', 'start': 246.72, 'duration': 3.04}, {'text': 'now these in some ways are gradual', 'start': 248.159, 'duration': 3.761}, {'text': 'changes overfishing poor quality poor', 'start': 249.76, 'duration': 4.8}, {'text': 'management climate change', 'start': 251.92, 'duration': 4.319}, {'text': 'but we also realize when we take our', 'start': 254.56, 'duration': 4.48}, {'text': 'recordings on an every day-to-day basis', 'start': 256.239, 'duration': 5.361}, {'text': 'we change the soundtrack of the ocean by', 'start': 259.04, 'duration': 4.64}, {'text': 'driving motorboats around millions of', 'start': 261.6, 'duration': 4.159}, {'text': 'motorboats every day drive around coral', 'start': 263.68, 'duration': 4.32}, {'text': 'reef environments with engines that', 'start': 265.759, 'duration': 4.961}, {'text': 'rattle with propellers that cavitate', 'start': 268.0, 'duration': 4.72}, {'text': 'creating bubbles which screech in the', 'start': 270.72, 'duration': 4.08}, {'text': 'water as they burst', 'start': 272.72, 'duration': 3.52}, {'text': \"and we've realized that this sound\", 'start': 274.8, 'duration': 3.92}, {'text': 'causes stress to all of the animals that', 'start': 276.24, 'duration': 5.04}, {'text': 'experience it and with stress comes poor', 'start': 278.72, 'duration': 3.68}, {'text': 'decisions', 'start': 281.28, 'duration': 2.88}, {'text': 'the fish are no longer able to respond', 'start': 282.4, 'duration': 4.48}, {'text': 'to predators to be able to find food to', 'start': 284.16, 'duration': 4.88}, {'text': 'be able to court to be able to', 'start': 286.88, 'duration': 4.16}, {'text': 'successfully reproduce', 'start': 289.04, 'duration': 4.8}, {'text': 'this motorboat noise is a form of noise', 'start': 291.04, 'duration': 5.04}, {'text': 'pollution that makes us realize we are', 'start': 293.84, 'duration': 5.84}, {'text': 'changing the soundtrack of the ocean', 'start': 296.08, 'duration': 5.679}, {'text': 'now if this was the end of the talk it', 'start': 299.68, 'duration': 4.079}, {'text': 'would be a sorry tale', 'start': 301.759, 'duration': 4.481}, {'text': 'but as a scientist i asked myself what', 'start': 303.759, 'duration': 5.361}, {'text': 'is my role what is my why am i', 'start': 306.24, 'duration': 5.12}, {'text': \"trying to do the science that i'm doing\", 'start': 309.12, 'duration': 6.56}, {'text': 'is my duty simply to monitor to measure', 'start': 311.36, 'duration': 6.8}, {'text': 'to assess how the world is changing and', 'start': 315.68, 'duration': 4.16}, {'text': 'to report that', 'start': 318.16, 'duration': 3.92}, {'text': 'or can we take that knowledge and can we', 'start': 319.84, 'duration': 4.16}, {'text': 'actually turn it into practical', 'start': 322.08, 'duration': 5.2}, {'text': \"solutions so here's um the the spiny\", 'start': 324.0, 'duration': 4.96}, {'text': 'chromis wonderful fish lives on the', 'start': 327.28, 'duration': 3.68}, {'text': 'great barrier reef in monogamous pairs a', 'start': 328.96, 'duration': 4.4}, {'text': 'male and female living together they lay', 'start': 330.96, 'duration': 4.16}, {'text': 'their eggs in the reef and their eggs', 'start': 333.36, 'duration': 4.64}, {'text': 'hatch and unusually they bring their', 'start': 335.12, 'duration': 6.24}, {'text': 'young through those first few weeks on', 'start': 338.0, 'duration': 5.52}, {'text': 'the reef they protect them and you can', 'start': 341.36, 'duration': 5.279}, {'text': 'see their baby fish out here the larvae', 'start': 343.52, 'duration': 6.08}, {'text': 'of the spiny chromis now if we monitor', 'start': 346.639, 'duration': 4.721}, {'text': 'how well they do near to boating', 'start': 349.6, 'duration': 4.0}, {'text': 'channels we realize that that motorboat', 'start': 351.36, 'duration': 4.88}, {'text': \"noise means that the adults don't feed\", 'start': 353.6, 'duration': 3.52}, {'text': 'as well', 'start': 356.24, 'duration': 2.88}, {'text': \"they don't defend the larvae against\", 'start': 357.12, 'duration': 3.519}, {'text': 'predators', 'start': 359.12, 'duration': 4.72}, {'text': 'in the same way so is that a real tragic', 'start': 360.639, 'duration': 6.4}, {'text': \"story of how with noise pollution we're\", 'start': 363.84, 'duration': 5.6}, {'text': 'affecting reproduction', 'start': 367.039, 'duration': 4.081}, {'text': 'or could it be that actually if we turn', 'start': 369.44, 'duration': 4.16}, {'text': 'it on its head we realize our comparison', 'start': 371.12, 'duration': 4.0}, {'text': \"is what happens if the boats aren't\", 'start': 373.6, 'duration': 3.68}, {'text': 'there could we be talking here about a', 'start': 375.12, 'duration': 3.28}, {'text': 'story of', 'start': 377.28, 'duration': 3.68}, {'text': 'acoustic protection if we go to the', 'start': 378.4, 'duration': 5.12}, {'text': 'great barrier reef and we play those sad', 'start': 380.96, 'duration': 5.12}, {'text': 'recordings of the current state of the', 'start': 383.52, 'duration': 5.44}, {'text': 'great barrier reef the fish no longer', 'start': 386.08, 'duration': 5.119}, {'text': 'arrive in the numbers that we would hope', 'start': 388.96, 'duration': 3.84}, {'text': 'for', 'start': 391.199, 'duration': 4.321}, {'text': 'if we play the recordings of the great', 'start': 392.8, 'duration': 5.04}, {'text': 'barrier reef as it used to be', 'start': 395.52, 'duration': 4.399}, {'text': 'the fish still come', 'start': 397.84, 'duration': 4.24}, {'text': 'so here are we talking about a story of', 'start': 399.919, 'duration': 4.72}, {'text': \"the loss of a sensory cue that's\", 'start': 402.08, 'duration': 4.959}, {'text': 'essential to close the loop of the life', 'start': 404.639, 'duration': 5.28}, {'text': 'cycle or could this be a story about the', 'start': 407.039, 'duration': 6.16}, {'text': 'potential value of acoustic enrichment', 'start': 409.919, 'duration': 5.361}, {'text': 'this is something that my group now are', 'start': 413.199, 'duration': 4.641}, {'text': 'actively pursuing around the world and', 'start': 415.28, 'duration': 4.8}, {'text': \"we're hugely excited that there are\", 'start': 417.84, 'duration': 3.84}, {'text': \"tools with acoustics that we're\", 'start': 420.08, 'duration': 4.8}, {'text': 'realizing might be part of the solution', 'start': 421.68, 'duration': 5.6}, {'text': \"so we realize it's our gift to change\", 'start': 424.88, 'duration': 4.64}, {'text': 'the soundtrack of the ocean in this', 'start': 427.28, 'duration': 3.919}, {'text': 'generation', 'start': 429.52, 'duration': 3.92}, {'text': 'but to change it for the better not the', 'start': 431.199, 'duration': 6.0}, {'text': 'worst with technology we can improve the', 'start': 433.44, 'duration': 5.68}, {'text': 'sound outputs of boat engines modern', 'start': 437.199, 'duration': 4.0}, {'text': 'engines are far quieter with', 'start': 439.12, 'duration': 4.639}, {'text': 'environmental protection we can keep', 'start': 441.199, 'duration': 4.801}, {'text': 'boats away from breeding grounds from', 'start': 443.759, 'duration': 4.72}, {'text': 'nursery grounds we can give quiet nights', 'start': 446.0, 'duration': 5.68}, {'text': 'to allow the fish to come in and settle', 'start': 448.479, 'duration': 5.201}, {'text': 'and with acoustic enrichment we can', 'start': 451.68, 'duration': 4.639}, {'text': 'potentially accelerate the recovery of', 'start': 453.68, 'duration': 6.639}, {'text': 'habitats that have been worst hit', 'start': 456.319, 'duration': 6.32}, {'text': 'steve simpson holds a phd from the', 'start': 460.319, 'duration': 4.401}, {'text': \"university of york and he's deeply\", 'start': 462.639, 'duration': 4.161}, {'text': 'devoted to reducing the impacts of', 'start': 464.72, 'duration': 4.64}, {'text': 'climate change on marine life', 'start': 466.8, 'duration': 4.32}, {'text': 'the tedx talk you just listened to was', 'start': 469.36, 'duration': 4.559}, {'text': 'recorded at a tedx event in exeter devon', 'start': 471.12, 'duration': 3.919}, {'text': 'england', 'start': 473.919, 'duration': 3.12}, {'text': 'all tedx events are independently', 'start': 475.039, 'duration': 4.481}, {'text': 'organized by volunteers who believe in', 'start': 477.039, 'duration': 5.681}, {'text': \"ted's mission of ideas worth spreading\", 'start': 479.52, 'duration': 5.359}, {'text': 'special thanks to the organizing team at', 'start': 482.72, 'duration': 4.159}, {'text': 'tedx exeter', 'start': 484.879, 'duration': 3.841}, {'text': 'want to hear more about this episode or', 'start': 486.879, 'duration': 4.0}, {'text': 'recommend the tedx talk for the show', 'start': 488.72, 'duration': 6.159}, {'text': 'visit our website at ted.com tedx shorts', 'start': 490.879, 'duration': 6.801}, {'text': \"i'm a tosa leone thanks for listening\", 'start': 494.879, 'duration': 6.521}, {'text': 'and see you next time', 'start': 497.68, 'duration': 3.72}]\n"
     ]
    }
   ],
   "source": [
    "srt = YouTubeTranscriptApi.get_transcript(str(video_id))\n",
    "transpt = srt\n",
    "print(transpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98416d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
